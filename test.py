# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'test.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QWidget
from PyQt5.QtMultimedia import *
from PyQt5.QtMultimediaWidgets import *
from PyQt5.QtCore import QTimer, QThread, Qt, pyqtSignal, pyqtSlot
from PyQt5.QtGui import QImage, QPixmap
import cv2
import numpy as np
import pandas as pd
import subprocess
import pickle
import json
from os import walk


class VideoThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)

    def __init__(self):
        super().__init__()
        self._run_flag = True

    def run(self):
        # capture from web cam
        cap = cv2.VideoCapture(0)
        while self._run_flag:
            ret, cv_img = cap.read()
            if ret:
                self.change_pixmap_signal.emit(cv_img)
        # shut down capture system
        cap.release()

    def stop(self):
        """Sets run flag to False and waits for thread to finish"""
        self._run_flag = False
        self.wait()

class RecordThread(QThread):
    
    def __init__(self, *args, **kwargs):
        super().__init__()
        self.active = True

    def run(self):
        if self.active:            
            self.fourcc = cv2.VideoWriter_fourcc(*'XVID') 
            self.out1 = cv2.VideoWriter('output.avi', self.fourcc, 25, (640,480))
            self.cap1 = cv2.VideoCapture(0, cv2.CAP_DSHOW)
            self.cap1.set(3, 480)
            self.cap1.set(4, 640)
            self.cap1.set(5, 25)
            while self.active:                      
                ret1, image1 = self.cap1.read()
                if ret1:
                    self.out1.write(image1)     
                self.msleep(10)                      

    def stop(self):
        self.out1.release()

class Ui_MainWindow(QWidget):
    def __init__(self):
        super().__init__()
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(1126, 727)
        MainWindow.setStyleSheet("background : lightgrey;")
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.horizontalLayoutWidget = QtWidgets.QWidget(self.centralwidget)
        self.horizontalLayoutWidget.setGeometry(QtCore.QRect(29, 0, 1071, 421))
        self.horizontalLayoutWidget.setObjectName("horizontalLayoutWidget")
        self.horizontalLayout = QtWidgets.QHBoxLayout(self.horizontalLayoutWidget)
        self.horizontalLayout.setContentsMargins(0, 0, 0, 0)
        self.horizontalLayout.setObjectName("horizontalLayout")
        self.L1 = QtWidgets.QLabel(self.horizontalLayoutWidget)
        font = QtGui.QFont()
        font.setFamily("Abyssinica SIL")
        font.setPointSize(24)
        self.L1.setFont(font)
        self.L1.setObjectName("L1")
        self.horizontalLayout.addWidget(self.L1)
        self.L2 = QtWidgets.QLabel(self.horizontalLayoutWidget)
        font = QtGui.QFont()
        font.setFamily("Abyssinica SIL")
        font.setPointSize(24)
        self.L2.setFont(font)
        self.L2.setObjectName("L2")
        self.horizontalLayout.addWidget(self.L2)
        self.animate = QtWidgets.QPushButton(self.centralwidget)
        self.animate.setGeometry(QtCore.QRect(120, 590, 131, 41))
        self.animate.setObjectName("animate")
        self.record = QtWidgets.QPushButton(self.centralwidget)
        self.record.setGeometry(QtCore.QRect(490, 590, 131, 41))
        self.record.setObjectName("record")
        self.record.clicked.connect(self.controlTimer)
        self.send = QtWidgets.QPushButton(self.centralwidget)
        self.send.setGeometry(QtCore.QRect(870, 590, 131, 41))
        self.send.setObjectName("send")
        self.send.clicked.connect(self.getFiles)
        self.textEdit = QtWidgets.QTextEdit(self.centralwidget)
        self.textEdit.setGeometry(QtCore.QRect(30, 450, 331, 70))
        self.textEdit.setObjectName("textEdit")
        self.label = QtWidgets.QLabel(self.centralwidget)
        self.label.setGeometry(QtCore.QRect(770, 450, 331, 71))
        self.label.setObjectName("label")
        MainWindow.setCentralWidget(self.centralwidget)
        self.saveTimer = QTimer()
        self.thread = VideoThread()
        # connect its signal to the update_image slot
        self.thread.change_pixmap_signal.connect(self.update_image)
        # start the thread
        self.thread.start()
        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.L1.setText(_translate("MainWindow", "Avatar"))
        self.L2.setText(_translate("MainWindow", "Video Feed"))
        self.L2.setWordWrap(True)
        self.animate.setText(_translate("MainWindow", "Animate"))
        self.record.setText(_translate("MainWindow", "Record"))
        self.send.setText(_translate("MainWindow", "Send"))
        self.label.setText(_translate("MainWindow", "Text Output"))
    
    def closeEvent(self, event):
        self.thread.stop()
        event.accept()

    @pyqtSlot(np.ndarray)
    def update_image(self, cv_img):
        """Updates the image_label with a new opencv image"""
        qt_img = self.convert_cv_qt(cv_img)
        self.L2.setPixmap(qt_img)
    
    def convert_cv_qt(self, cv_img):
        """Convert from an opencv image to QPixmap"""
        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        bytes_per_line = ch * w
        convert_to_Qt_format = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
        p = convert_to_Qt_format.scaled(535, 421, Qt.KeepAspectRatio)
        return QPixmap.fromImage(p)

    @QtCore.pyqtSlot(QImage)
    def setImage(self, qImg1):
        self.image_label.setPixmap(QPixmap.fromImage(qImg1))

    def controlTimer(self):
        if not self.saveTimer.isActive():
            # write video
            self.saveTimer.start()
            self.th2 = RecordThread(self)
            self.th2.active = True                                
            self.th2.start()
            # update control_bt text
            self.record.setText("STOP")
        else:
            # stop writing
            self.saveTimer.stop()
            self.th2.active = False                   
            self.th2.stop()                         
            self.th2.terminate()                    
            # update control_bt text
            self.record.setText("Record")

    def inference(self):
        "This function runs the command for slowfast model"
        ## Reading segmented videos and preparing for inference
        root_dir = '/media/dell/HDD/ASL/'
        f = []
        for (dirpath, dirnames, filenames) in walk("./outSegments"):
            f.extend(filenames)
            break

        f = [root_dir + 'outSegments/'+x for x in f]
        SEPARATOR = ' '
        df_test = pd.DataFrame({'X': [X + SEPARATOR + "0" for X in f]})
        df_test.to_csv(root_dir + 'test.csv', index=False, header=None)
        #command to run the slowfast model
        command_asl = """
        python slowfast/tools/run_net.py \
        --cfg slowfast/configs/Kinetics/c2/SLOWFAST_8x8_R50.yaml NUM_GPUS 2 \
        DATA.PATH_TO_DATA_DIR . \
        TEST.CHECKPOINT_FILE_PATH ./Results/output-100-25fps/checkpoints/checkpoint_epoch_00196.pyth \
        TRAIN.ENABLE False
        """
        subprocess.run(command_asl, shell=True)
        print("finished inference")

    def getOutput(self):
        with open('/home/dell/ASL/predictions.pkl', 'rb') as f:
            data = pickle.load(f)
        # read the dataset classes
        top_N = 2000
        f = open('/media/dell/HDD/ASL/WLASL_v0.3.json',)
        dataset_info = json.load(f)
        top_N_obj = (dataset_info[:top_N])

        #get label for each prediction
        indicies = np.array(data[0]).astype(int)
        sentenc = [top_N_obj[x]['gloss'] for x in indicies]
        self.L2.setText(' '.join(sentenc))

    def getFiles(self):
        fileName, _ = QtWidgets.QFileDialog.getOpenFileName(self, 'Single File', QtCore.QDir.rootPath() , '*.mp4')
        self.label.setText(fileName)
        #command to run the segmention module
        subprocess.run(["python3", "seg.py", "--video_path", fileName])
        print("finished segmentation")
        self.inference()
        self.getOutput()

        
        



            
if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
